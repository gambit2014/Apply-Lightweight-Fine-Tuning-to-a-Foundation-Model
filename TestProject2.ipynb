{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ed0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, dataset_dict, tokenizer, split=\"train\", max_length=512):\n",
    "        self.dataset = dataset_dict[split]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        # Combine title and text for better context\n",
    "        text = f\"{item['text']}\"\n",
    "        \n",
    "        # length and proper padding\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_tensors=None  # Don't return as tensors yet\n",
    "        )\n",
    "        \n",
    "       \n",
    "        input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n",
    "        \n",
    "        # labels for language modeling\n",
    "        labels = input_ids.clone()\n",
    "        labels[attention_mask == 0] = -100  \n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4a7c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/student/.local/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: huggingface_hub in /home/student/.local/lib/python3.10/site-packages (0.27.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/student/.local/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: packaging in /home/student/.local/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927ef3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80324c6e992d49f3941dc2823fedd252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb2b8cc3d0240d6a219959fcce3479d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80027122b17f4257ad1905b1dce153bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264d3ea8b0434f37a809bd8f91e52507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827235e74553442e9eb8690b6fce0377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Train size: 120000\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "print(f\"Dataset loaded. Train size: {len(dataset['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb505774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7b49c2514a419fa87b26d75170ada7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21638e8da6f14932ba8230bb35e5195c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cf97e023444e739e398ba94b5b968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d2173322294272ae7e52790027db0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False  # For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b44c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 120000\n",
      "Test dataset size: 7600\n",
      "\n",
      "Sample output keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "Sample output shapes:\n",
      "input_ids: torch.Size([512])\n",
      "attention_mask: torch.Size([512])\n",
      "labels: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Create custom datasets\n",
    "train_dataset = AGNewsDataset(dataset, tokenizer, \"train\")\n",
    "test_dataset = AGNewsDataset(dataset, tokenizer, \"test\")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Verify dataset output format\n",
    "sample_output = train_dataset[0]\n",
    "print(\"\\nSample output keys:\", sample_output.keys())\n",
    "print(\"Sample output shapes:\")\n",
    "for key, val in sample_output.items():\n",
    "    print(f\"{key}: {val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324e0b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters:\n",
      "trainable params: 405,504 || all params: 124,845,312 || trainable%: 0.32480514766946156\n"
     ]
    }
   ],
   "source": [
    "# LoRA config\n",
    "config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# LoRA to the model\n",
    "lora_model = get_peft_model(model, config)\n",
    "print(\"\\nTrainable parameters:\")\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "# cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, #tried 16,8 \n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_steps=500,\n",
    "    fp16=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Start\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0316a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving model...\")\n",
    "lora_model.save_pretrained(\"ag_news_gpt2_lora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adbc3185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating fine-tuned model...\n",
      "Fine-tuned Model Perplexity: 72.18\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataset, tokenizer, batch_size=8):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # dataset in batches\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            end_idx = min(i + batch_size, len(dataset))\n",
    "            \n",
    "            \n",
    "            batch_items = [dataset[j] for j in range(i, end_idx)]\n",
    "            input_ids = torch.stack([item['input_ids'] for item in batch_items]).to(device)\n",
    "            attention_mask = torch.stack([item['attention_mask'] for item in batch_items]).to(device)\n",
    "            labels = torch.stack([item['labels'] for item in batch_items]).to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item() * (end_idx - i)\n",
    "            total_samples += (end_idx - i)\n",
    "    \n",
    "    return total_loss / total_samples\n",
    "\n",
    "# Now evaluate the model\n",
    "print(\"\\nEvaluating fine-tuned model...\")\n",
    "try:\n",
    "    finetuned_loss = evaluate_model(lora_model, test_dataset, tokenizer)\n",
    "    finetuned_perplexity = torch.exp(torch.tensor(finetuned_loss))\n",
    "    print(f\"Fine-tuned Model Perplexity: {finetuned_perplexity:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {str(e)}\")\n",
    "    print(\"Let's check the dataset structure:\")\n",
    "    sample_item = test_dataset[0]\n",
    "    print(\"\\nSample dataset item structure:\")\n",
    "    for key, value in sample_item.items():\n",
    "        print(f\"{key}: {type(value)}, shape: {value.shape if hasattr(value, 'shape') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b714c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying saved model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample generation:\n",
      "Wall Street on Monday as the Federal Reserve's decision to raise interest rates on its $1.25 trillion bond-buying program was announced.\n",
      "\n",
      "The Fed's decision to raise rates on its $1.25 trillion bond-buying program was announced Monday.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"\\nVerifying saved model...\")\n",
    "loaded_model = AutoPeftModelForCausalLM.from_pretrained(\"ag_news_gpt2_lora\")\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "# Test generation\n",
    "test_text = \"Wall Street on Monday as\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "outputs = loaded_model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=50)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"\\nSample generation:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365d887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional Generation Examples:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: The technology  announced\n",
      "Generated: The technology  announced by the company is a \"smart\" way to detect and track the movement of a person's body.\n",
      "\n",
      "The company is also developing a new way to track the movement of a person's body.\n",
      "\n",
      "The company is also developing a new way to track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: In sports , the team\n",
      "Generated: In sports, the team's goal is to win the championship.\n",
      "\n",
      "\"We're not going to be a team that's going to win the championship,\" said coach Mike Krzyzewski. \"We're going to be a team that's going to win the championship. We're\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: The economy  signs of\n",
      "Generated: The economy  signs of recovery  and the economy  signs of recovery  and the economy  signs of recovery  and the economy  signs of recovery  and the economy  signs of recovery  and the economy  signs of recovery  and the economy  signs\n",
      "\n",
      "Prompt: Scientists a new\n",
      "Generated: Scientists a new study of the effects of the Zika virus on the brain of a young girl who was infected with the virus has found that the virus can cause a brain abnormality.\n",
      "\n",
      "The girl, who was born with a brain abnormality, was infected with the virus in\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    \"The technology  announced\",\n",
    "    \"In sports , the team\",\n",
    "    \"The economy  signs of\",\n",
    "    \"Scientists a new\"\n",
    "]\n",
    "\n",
    "print(\"\\nAdditional Generation Examples:\")\n",
    "for prompt in test_prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = loaded_model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=53)\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"Generated:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c09fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
